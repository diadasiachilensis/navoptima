{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24637df4",
   "metadata": {},
   "source": [
    "# Estrategia de Modelado Predictivo (ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57f9cb8",
   "metadata": {},
   "source": [
    "**Proyecto:** Optimizaci√≥n de Eficiencia Energ√©tica Naval\n",
    "**Fase:** Selecci√≥n de Arquitectura y Entrenamiento (Model Tournament)\n",
    "\n",
    "---\n",
    "\n",
    "**Objetivo del M√≥dulo**\n",
    "\n",
    "Desarrollar y comparar modelos de Machine Learning para predecir el consumo de combustible (`log_fuel_consumption`), superando las limitaciones de linealidad detectadas en el Baseline F√≠sico (OLS).\n",
    "\n",
    "**Contexto T√©cnico (Heredado del EDA)**\n",
    "\n",
    "El an√°lisis exploratorio revel√≥ tres factores cr√≠ticos que definen la estrategia de modelado:\n",
    "1.  **No-Linealidad Estructural:** La \"Ley del Cubo\" te√≥rica se ve distorsionada a baja velocidad por la Carga Base (*Hotel Load*), creando un efecto de \"banana\" que la regresi√≥n lineal no captura bien.\n",
    "2.  **Autocorrelaci√≥n Severa:** El test de Durbin-Watson (0.01) confirm√≥ que los datos dependen fuertemente del tiempo.\n",
    "3.  **Multicolinealidad:** La variable `width` fue eliminada; el modelo debe manejar la interacci√≥n entre `length` y `draft` para deducir la resistencia.\n",
    "\n",
    "**Estrategia de Validaci√≥n (Rules of Engagement)**\n",
    "\n",
    "Para garantizar resultados realistas y evitar *Data Leakage*:\n",
    "* **Prohibido `shuffle=True`:** No mezclaremos datos aleatoriamente.\n",
    "* **Split Cronol√≥gico:** Entrenaremos estrictamente con el **Pasado (80%)** y evaluaremos con el **Futuro (20%)**.\n",
    "* **M√©trica Decisiva:** RMSE (Root Mean Squared Error) para penalizar grandes desviaciones.\n",
    "\n",
    "---\n",
    "**Los Modelos a evaluar**\n",
    "\n",
    "1.  **Baseline:** Regresi√≥n Lineal (OLS) - *Referencia de \"suelo\" de rendimiento.*\n",
    "2.  **Retador 1:** Random Forest Regressor - *Captura de no-linealidad robusta.*\n",
    "3.  **Retador 2:** XGBoost Regressor - *Boosting de alto rendimiento para Big Data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f42255",
   "metadata": {},
   "source": [
    "## Instalacion librerias y configuracion de Entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f965229b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Entorno Configurado Exitosamente.\n",
      "   - Pandas Version: 2.3.3\n",
      "   - XGBoost Version: 3.1.2\n",
      "   - Estrategia: TimeSeriesSplit cargado.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# M√©tricas de Evaluaci√≥n\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# Herramientas de Validaci√≥n (Series de Tiempo)\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "# Modelos\n",
    "from sklearn.linear_model import LinearRegression   # Benchmark (L√≠nea Base)\n",
    "from sklearn.ensemble import RandomForestRegressor  # Retador 1 (No linealidad)\n",
    "import xgboost as xgb                               # Retador 2 (Potencia Big Data)\n",
    "\n",
    "# --- Configuraci√≥n Global ---\n",
    "# Estilo de gr√°ficos limpio\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Configuraci√≥n de Pandas para ver todas las columnas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "\n",
    "# Silenciar advertencias molestas de versiones futuras\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Entorno Configurado Exitosamente.\")\n",
    "print(f\"   - Pandas Version: {pd.__version__}\")\n",
    "print(f\"   - XGBoost Version: {xgb.__version__}\")\n",
    "print(\"   - Estrategia: TimeSeriesSplit cargado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9aa995",
   "metadata": {},
   "source": [
    "## Funci√≥n de Evaluaci√≥n Estandarizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cf8ad98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Funci√≥n 'train_evaluate_model' definida. El sistema de arbitraje est√° listo.\n"
     ]
    }
   ],
   "source": [
    "def train_evaluate_model(model, model_name, X_train, y_train, X_test, y_test):\n",
    "    \"\"\" Entrena el modelo y eval√∫a su desempe√±o en train y test para detectar overfitting.\n",
    "    \n",
    "    Args:\n",
    "        model: Estimador de scikit-learn o xgboost inicializado.\n",
    "        model_name (str): Nombre identificador.\n",
    "    \n",
    "    Returns:\n",
    "        dict: M√©tricas calculadas.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Entrenamiento\n",
    "    print(f\"üîÑ Entrenando {model_name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 2. Predicci√≥n (Train y Test)\n",
    "    # Predecimos en ambos para medir la brecha (Generalizaci√≥n vs Memorizaci√≥n)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # 3. C√°lculo de M√©tricas\n",
    "    # RMSE (Root Mean Squared Error): Penaliza cuadr√°ticamente los errores grandes.\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    \n",
    "    # MAE (Mean Absolute Error): Error promedio directo (m√°s interpretable).\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    \n",
    "    # R2 (Coeficiente de Determinaci√≥n): Capacidad explicativa de la varianza.\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    # 4. Reporte T√©cnico en Consola\n",
    "    print(f\"\\nüìä Resultados para: {model_name}\")\n",
    "    print(f\"{'-'*30}\")\n",
    "    print(f\"‚Ä¢ RMSE Train: {rmse_train:.4f}\")\n",
    "    print(f\"‚Ä¢ RMSE Test:  {rmse_test:.4f}\")\n",
    "    print(f\"‚Ä¢ Delta RMSE: {rmse_test - rmse_train:.4f} (Gap de Overfitting)\")\n",
    "    print(f\"‚Ä¢ MAE Test:   {mae_test:.4f}\")\n",
    "    print(f\"‚Ä¢ R¬≤ Test:    {r2_test:.4f}\")\n",
    "    print(f\"{'='*30}\\n\")\n",
    "    \n",
    "    return {\n",
    "        'Modelo': model_name,\n",
    "        'RMSE_Test': rmse_test,\n",
    "        'RMSE_Train': rmse_train,\n",
    "        'MAE_Test': mae_test,\n",
    "        'R2_Test': r2_test\n",
    "    }\n",
    "\n",
    "# Lista para guardar los resultados del torneo\n",
    "results_list = []\n",
    "\n",
    "print(\"‚úÖ Funci√≥n 'train_evaluate_model' definida. El sistema de arbitraje est√° listo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dc53a3",
   "metadata": {},
   "source": [
    "**Puntos Clave:**\n",
    "\n",
    "1. Delta RMSE: Calculamos la diferencia entre el error de entrenamiento y el de prueba. Si este n√∫mero es muy alto, el modelo est√° haciendo Overfitting (memorizando en vez de aprender).\n",
    "\n",
    "2. M√©trica Dual (RMSE vs MAE): RMSE es m√°s sensible a los valores at√≠picos (picos de consumo), mientras que MAE nos da una idea del error \"en el d√≠a a d√≠a\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96e0985",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60d88df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELDA 3: FASE 1 - Benchmark (Regresi√≥n Lineal OLS) ---\n",
    "\n",
    "# 1. Inicializar el modelo base\n",
    "# Usamos los par√°metros por defecto. No requiere ajuste de hiperpar√°metros.\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# 2. Entrenar y Evaluar usando la funci√≥n del √°rbitro\n",
    "# Pasamos los datos de Train (Pasado) y Test (Futuro)\n",
    "print(\"üèÅ Iniciando Benchmark...\")\n",
    "lr_results = train_evaluate_model(\n",
    "    model=lr_model,\n",
    "    model_name=\"Baseline (Regresi√≥n Lineal)\",\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test\n",
    ")\n",
    "\n",
    "# 3. Guardar resultados en el tablero del torneo\n",
    "results_list.append(lr_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610d96e1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
