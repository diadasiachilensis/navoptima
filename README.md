# **üß≠ Navoptima: Plataforma de Ingenier√≠a de Datos para Predicci√≥n de Churn**

![Python](https://img.shields.io/badge/Python-3.11-blue?style=for-the-badge&logo=python&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-Container-blue?style=for-the-badge&logo=docker&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109-009688?style=for-the-badge&logo=fastapi&logoColor=white)
![Postgres](https://img.shields.io/badge/PostgreSQL-16-336791?style=for-the-badge&logo=postgresql&logoColor=white)
![Jupyter](https://img.shields.io/badge/Jupyter-F37626.svg?style=for-the-badge&logo=Jupyter&logoColor=white)
![Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=for-the-badge&logo=Apache%20Airflow&logoColor=white)
![Power Bi](https://img.shields.io/badge/power_bi-F2C811?style=for-the-badge&logo=powerbi&logoColor=black)
![Spark](https://img.shields.io/badge/Apache%20Spark-E25A1C?style=for-the-badge&logo=apachespark&logoColor=white)
![Delta Lake](https://img.shields.io/badge/Delta%20Lake-black?style=for-the-badge&logo=deltalake&logoColor=white)
![Amazon S3](https://img.shields.io/badge/Amazon%20S3-569A31?style=for-the-badge&logo=amazons3&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=for-the-badge&logo=fastapi)
![Kubernetes](https://img.shields.io/badge/kubernetes-326CE5?style=for-the-badge&logo=kubernetes&logoColor=white)

Este documento proporciona una visi√≥n detallada del proyecto de ingenier√≠a de datos **Navoptima**. Su objetivo es servir como una gu√≠a central para desarrolladores, ingenieros y stakeholders, detallando los objetivos, la arquitectura del sistema, la pila tecnol√≥gica y las instrucciones para su despliegue y ejecuci√≥n.

## **üìù Resumen del Proyecto**

**Navoptima** es una plataforma de ingenier√≠a de datos de alto rendimiento dise√±ada para procesar y analizar flujos de eventos en tiempo real y por lotes.

El proyecto resuelve el desaf√≠o cr√≠tico de transformar datos crudos y vol√°tiles en insights accionables y predicciones de baja latencia, permitiendo a la organizaci√≥n optimizar sus operaciones de negocio, como la **\[predicci√≥n de abandono de clientes\]**, con agilidad y precisi√≥n.

## **üìë Tabla de Contenidos**

1. [Objetivos del Negocio y T√©cnicos](https://www.google.com/search?q=%23-1-objetivos-del-negocio-y-t%C3%A9cnicos)  
2. [Arquitectura del Sistema](https://www.google.com/search?q=%23-2-arquitectura-del-sistema)  
3. [Pila Tecnol√≥gica (Tech Stack)](https://www.google.com/search?q=%23-3-pila-tecnol%C3%B3gica-tech-stack)  
4. [C√≥mo Empezar (Getting Started)](https://www.google.com/search?q=%23-4-c%C3%B3mo-empezar-getting-started)  
5. [Estructura del Proyecto](https://www.google.com/search?q=%23-5-estructura-del-proyecto)  
6. [Licencia](https://www.google.com/search?q=%23-6-licencia)

## **üéØ 1\. Objetivos del Negocio y T√©cnicos**

Un principio fundamental en el dise√±o de sistemas de Machine Learning es la alineaci√≥n estricta entre los objetivos t√©cnicos y las m√©tricas de negocio. El √©xito de un proyecto de datos no se mide por la precisi√≥n del modelo en un vac√≠o, sino por su capacidad para generar un impacto tangible en los indicadores clave del negocio. **Navoptima** se ha dise√±ado con esta filosof√≠a en su n√∫cleo.

### **1.1. Problema de Negocio**

La organizaci√≥n necesita una capacidad proactiva para identificar a los clientes en riesgo de abandonar el servicio (*churn*). Las soluciones existentes procesan los datos de forma peri√≥dica (diaria o semanal), lo que genera una ventana de tiempo demasiado amplia durante la cual se pierden oportunidades de retenci√≥n.

**Soluci√≥n:** Navoptima aborda este problema proporcionando predicciones casi en tiempo real sobre la probabilidad de abandono, permitiendo intervenciones personalizadas y oportunas.

### **1.2. Objetivos T√©cnicos**

Para resolver el problema de negocio, la arquitectura debe equilibrar el inherente *trade-off* entre el rendimiento del procesamiento por lotes y la latencia de las predicciones en tiempo real. Se han definido los siguientes objetivos t√©cnicos clave:

* **‚ö° Alto Rendimiento (High Throughput):** Para garantizar que nuestros modelos de ML se entrenen con datos completos y precisos, el sistema debe procesar de manera eficiente grandes vol√∫menes de datos hist√≥ricos. Este enfoque por lotes es fundamental para el an√°lisis exploratorio y el reentrenamiento peri√≥dico de los modelos.  
* **‚è±Ô∏è Baja Latencia (Low Latency):** Para el caso de uso de predicci√≥n de abandono, servir predicciones con un retardo m√≠nimo es cr√≠tico para habilitar intervenciones proactivas y oportunas (ej. ofrecer un descuento personalizado) antes de que un cliente finalice su decisi√≥n de abandonar el servicio.  
* **üîÑ Idempotencia:** Para lograr un procesamiento de datos fiable, nuestros pipelines deben ser resilientes a fallos y reejecuciones. Al implementar *Idempotency Design Patterns* como el **Merger pattern**, garantizamos que la reejecuci√≥n de un trabajo no introduzca datos duplicados ni corrompa el estado del sistema, lo cual es fundacional para la integridad de nuestro *feature store*.  
* **üíé Calidad de Datos:** El poder predictivo de nuestros modelos depende directamente de la integridad de los datos de entrada. Para garantizarla, aplicamos el patr√≥n **Constraints Enforcer**, que valida que solo los datos que cumplen con un esquema y reglas de negocio predefinidas sean procesados, previniendo que datos de mala calidad se propaguen por el sistema.

La siguiente arquitectura es una respuesta directa a estos requisitos t√©cnicos, con cada componente y patr√≥n de dise√±o elegido para satisfacer uno o m√°s de estos objetivos.

## **üèóÔ∏è 2\. Arquitectura del Sistema**

La arquitectura de Navoptima est√° estructurada siguiendo las fases del **Ciclo de Vida de la Ingenier√≠a de Datos (Data Engineering Lifecycle)**. Este enfoque sist√©mico no solo garantiza un flujo de datos coherente, sino que tambi√©n nos permite aislar, optimizar y escalar cada fase de manera independiente, una decisi√≥n clave para la mantenibilidad y evoluci√≥n del sistema a largo plazo.

### **2.1. Descripci√≥n General**

El flujo de datos de alto nivel sigue la secuencia de procesamiento definida por el ciclo de vida del dato:

1. **Fuentes de Datos (Generation):** Sistemas transaccionales y de eventos generan los datos crudos.  
2. **Almacenamiento (Storage):** Los datos crudos y procesados se almacenan en un sistema optimizado para escalabilidad y acceso eficiente.  
3. **Ingesta (Ingestion):** Los datos son capturados desde las fuentes y transportados a nuestra capa de transformaci√≥n.  
4. **Transformaci√≥n (Transformation):** Los datos crudos se limpian, enriquecen y modelan para su uso en an√°lisis y Machine Learning.  
5. **Servicio de Datos (Serving):** Los datos procesados y las predicciones del modelo se exponen a los sistemas consumidores.

### **2.2. Fases del Ciclo de Vida del Dato**

#### **üì° Fuentes de Datos (Generation)**

Navoptima se alimenta de una variedad de sistemas de origen, incluyendo bases de datos de aplicaciones **OLTP** (con un *fixed schema*) que registran las transacciones de los usuarios y flujos de eventos de telemetr√≠a (considerados *schemaless*) que capturan las interacciones en tiempo real. Esta diversidad requiere una arquitectura de almacenamiento e ingesta flexible.

#### **üíæ Almacenamiento (Storage)**

Nuestra arquitectura se basa en un enfoque **Data Lakehouse**, una decisi√≥n estrat√©gica para combinar la flexibilidad de un Data Lake ‚Äîideal para almacenar los flujos de eventos *schemaless*‚Äî con las garant√≠as transaccionales **ACID** y el rendimiento de un Data Warehouse, que es esencial para el consumo por parte de herramientas de BI y analistas.

La base de nuestro almacenamiento es un *object store* (ej. Amazon S3) con un formato de tabla abierta (ej. Delta Lake), lo que implementa el principio clave de **Separaci√≥n de C√≥mputo y Almacenamiento**. Esto nos permite escalar los recursos de procesamiento y almacenamiento de forma independiente, optimizando costos y rendimiento.

#### **üì• Ingesta (Ingestion)**

Para satisfacer el *trade-off* entre alto rendimiento y baja latencia, la estrategia de ingesta es h√≠brida.

* **Batch:** Para el procesamiento por lotes que alimenta el reentrenamiento de modelos, empleamos patrones como el **Incremental Loader** para cargar eficientemente solo los cambios diferenciales, satisfaciendo el objetivo de Alto Rendimiento.  
* **Real-time:** Para las predicciones de abandono en tiempo real, se implementa una ingesta por streaming que captura cambios de la base de datos (**CDC**) a trav√©s de un **Passthrough Replicator**, garantizando la Baja Latencia necesaria para intervenciones oportunas.

#### **üîÑ Transformaci√≥n (Transformation)**

Adoptamos un modelo **ELT (Extract, Load, Transform)**, que es la elecci√≥n natural para una arquitectura Lakehouse. Al cargar primero los datos crudos en el almacenamiento de bajo costo, podemos aprovechar el principio de 'Separaci√≥n de C√≥mputo y Almacenamiento' para aplicar transformaciones complejas utilizando motores de procesamiento distribuido potentes como **Spark**. Este enfoque es m√°s escalable y rentable que el ETL tradicional.

Durante esta fase, aplicamos patrones clave como el **Merger pattern** para la idempotencia en las operaciones de actualizaci√≥n y el **Data Enrichment** para a√±adir valor contextual a los datos.

#### **üì§ Servicio de Datos (Serving Data)**

Los resultados finales se exponen de dos maneras, equilibrando el *trade-off* entre latencia y rendimiento:

1. **Tablas Agregadas:** Disponibles en el Data Lakehouse para que los analistas de negocio y cient√≠ficos de datos las consuman a trav√©s de herramientas de BI o notebooks.  
2. **API de Predicci√≥n:** Un microservicio de baja latencia que expone las predicciones del modelo para el consumo s√≠ncrono por parte de las aplicaciones cliente.

La implementaci√≥n de esta arquitectura se apoya en un conjunto de tecnolog√≠as cuidadosamente seleccionadas por su robustez, escalabilidad y madurez en el ecosistema de datos.

## **üõ†Ô∏è 3\. Pila Tecnol√≥gica (Tech Stack)**

La siguiente tabla resume las tecnolog√≠as clave utilizadas en el proyecto Navoptima, agrupadas por su funci√≥n dentro del ciclo de vida del dato.

| Categor√≠a | Tecnolog√≠as |
| :---- | :---- |
| **Orquestaci√≥n de Flujos** | Apache Airflow, Dagster |
| **Procesamiento de Datos** | Apache Spark, Apache Flink |
| **Streaming y Mensajer√≠a** | Apache Kafka, Amazon Kinesis |
| **Almacenamiento** | Delta Lake, PostgreSQL, Amazon S3 |
| **Servicio de Predicciones** | API REST con FastAPI, Seldon Core |
| **Contenerizaci√≥n** | Docker, Kubernetes (K8s) |

## **üöÄ 4\. C√≥mo Empezar (Getting Started)**

Sigue estos pasos para configurar y ejecutar una versi√≥n local del entorno de desarrollo del proyecto.

### **4.1. Prerrequisitos**

Aseg√∫rate de tener instaladas las siguientes herramientas en tu m√°quina local:

* Python 3.9+  
* Docker y Docker Compose  
* make

### **4.2. Instalaci√≥n**

Ejecuta los siguientes comandos en tu terminal para clonar el repositorio e instalar todas las dependencias necesarias.

\# Clona este repositorio  
git clone \[https://github.com/diadasiachilensis/navoptima.git\](https://github.com/diadasiachilensis/navoptima.git)  
cd navoptima

\# Instala las dependencias de Python  
pip install \-r requirements.txt

\# Construye las im√°genes de Docker y levanta los servicios de infraestructura  
\# (ej. base de datos, Kafka) definidos en docker-compose.yml.  
make build  
make up

### **4.3. Ejecuci√≥n**

Para iniciar un pipeline espec√≠fico, utiliza el siguiente comando. Por ejemplo, para ejecutar el DAG que procesa las caracter√≠sticas diarias de abandono de clientes:

\# Ejemplo para ejecutar un pipeline espec√≠fico  
make run-pipeline pipeline\_name=process\_daily\_churn\_features

## **üìÇ 5\. Estructura del Proyecto**

La estructura del repositorio est√° organizada para separar claramente las distintas responsabilidades del proyecto.

navoptima/  
‚îú‚îÄ‚îÄ data/              \# Scripts y ficheros relacionados con datos (ej. seeds, schemas)  
‚îú‚îÄ‚îÄ notebooks/         \# Notebooks para an√°lisis exploratorio y experimentaci√≥n  
‚îú‚îÄ‚îÄ src/               \# C√≥digo fuente principal de la aplicaci√≥n y los pipelines  
‚îú‚îÄ‚îÄ tests/             \# Pruebas unitarias y de integraci√≥n  
‚îú‚îÄ‚îÄ .env.example       \# Plantilla para variables de entorno  
‚îú‚îÄ‚îÄ docker-compose.yml \# Definici√≥n de servicios para el entorno local  
‚îú‚îÄ‚îÄ Dockerfile         \# Fichero para construir la imagen de Docker de la aplicaci√≥n  
‚îú‚îÄ‚îÄ LICENSE.txt        \# Licencia del proyecto  
‚îî‚îÄ‚îÄ README.md          \# Esta documentaci√≥n

## **üìÑ 6\. Licencia**

Distribuido bajo la **Licencia MIT**. Consulta LICENSE.txt para obtener m√°s informaci√≥n.
